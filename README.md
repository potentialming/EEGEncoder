<<<<<<< HEAD
# EEG2Gaussian

> **Decoding and Visualizing Visualâ€‘Evoked EEG for VR Scenes Using 3D Gaussian Splatting**

This repository hosts the **official implementation** of the paper **â€œEEG2Gaussian:Â Decoding and Visualizing Visualâ€‘Evoked EEG for VR Scenes Using 3D Gaussian Splatting.â€** It provides everything you need to reproduce the experimentsâ€”from EEG signal decoding and visionâ€“language alignment to final 3D Gaussianâ€‘Splatting reconstruction.

![alt text](images/teaser.png)

---

## ðŸ—‚ï¸ Project Layout

```text
EEG2GAUSSIAN/
â”œâ”€â”€ NTF-Encoder/           # Core models & training scripts
â”‚Â Â  â”œâ”€â”€ dataset.py                 # EEG / image loading & preprocessing
â”‚Â Â  â”œâ”€â”€ model_imagenet.py          # EEG encoder for pure classification
â”‚Â Â  â”œâ”€â”€ model_imagenet_clip.py     # EEG encoder with CLIPâ€‘alignment head
â”‚Â Â  â”œâ”€â”€ train_ImageNet.py          # ImageNetâ€‘style classification training
â”‚Â Â  â””â”€â”€ train_ImageNet_clip.py     # Joint classification + alignment training
â”‚
â”œâ”€â”€ results/               # Autoâ€‘generated weights, logs, plots
â””â”€â”€ README.md              # You are here
```

---

## âœ¨ Highlights

- **EEGÂ â‡„Â Image Semantic Alignment** â€“ Uses [OpenAIÂ CLIP](https://github.com/openai/CLIP) embeddings to explicitly pull EEG features into the visualâ€“semantic space.
- **Pluggable NTFâ€‘Encoder** â€“ A lightweight, dualâ€‘domain attention network that works with ImageNetâ€‘EEG, 360â€‘EEG, and more.
- **Oneâ€‘Click Training & Evaluation** â€“ `train_ImageNet_clip.py` performs joint classification + alignment training and automatically saves the best checkpoint.
- **3D Gaussian Splatting Output** â€“ Converts Stableâ€‘Diffusion panoramas to Gaussian point clouds for immersive VR visualization (to be openâ€‘sourced soon).

---

## âš™ï¸ Requirements

| Package                      | Version          | Notes                                                |
| ---------------------------- | ---------------- | ---------------------------------------------------- |
| Python                       | â‰¥Â 3.8            |                                                      |
| PyTorch                      | â‰¥Â 1.13           | CUDAÂ 11 recommended                                  |
| torchvision                  | matching PyTorch |                                                      |
| numpy / scipy / scikitâ€‘learn | latest           | Signal processing & PCA                              |
| pillow                       | â‰¥Â 9.0            | Image I/O                                            |
| ftfy / regex                 | latest           | CLIP dependencies                                    |
| **openaiâ€‘clip**              | latest           | `pip install git+https://github.com/openai/CLIP.git` |

### Quick Setup

```bash
conda create -n eeg2gs python=3.10 -y
conda activate eeg2gs
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118
pip install numpy scipy scikit-learn pillow ftfy regex tqdm
pip install git+https://github.com/openai/CLIP.git
```

---

## ðŸ“¦ Data Preparation

### 1. ImageNetâ€‘EEG

1. Place `eeg_5_95_std.pth` and `block_splits_by_image_single.pth` under `./dataset/ImageNet/EEG/`.
2. Download the corresponding ImageNet images to `./dataset/ImageNet/imageNet_images/` (or symlink the folder).

> A helper inside `NTF-Encoder/dataset.py` can convert raw `.mat`/`.edf` EEG files to the `.pth` format above if you wish to start from scratch.

### 2. 360â€‘EEG (optional)

Align 360Â° panoramas with your EEG recordings and point `EEGDataset_360EEG` to the new pathsâ€”no other changes required.

---

## ðŸš€ Training & Evaluation

### 1ï¸âƒ£  Joint ImageNetÂ +Â CLIP Training

```bash
python NTF-Encoder/train_ImageNet_clip.py \
  --data_path   ./dataset/ImageNet/EEG/eeg_5_95_std.pth \
  --images_path ./dataset/ImageNet/imageNet_images \
  --split_file  ./dataset/ImageNet/block_splits_by_image_single.pth \
  --batch_size 32 --epochs 200 --lr 3e-4
```

During training the script creates a timeâ€‘stamped folder in `./results/imageNet_clip/` containing:

- `best_eeg_encoder.pth`Â â€” checkpoint with the lowest validation loss
- `train_val_loss.png`Â â€” loss curves
- `results.txt`Â â€” topâ€‘1 accuracy and embeddingâ€‘matching accuracy

### 2ï¸âƒ£  Classificationâ€‘Only Baseline

```bash
python NTF-Encoder/train_ImageNet.py --help  # full list of options
```

### 3ï¸âƒ£  Inference / Feature Extraction

```python
import torch
from model_imagenet_clip import EEGEncoder
model = EEGEncoder().eval()
model.load_state_dict(torch.load('best_eeg_encoder.pth'))
with torch.no_grad():
    logits, eeg_embed, _ = model(eeg_tensor)  # eeg_tensor: (B, C, T)
```

---

## ðŸ“ˆ Reproducing Our Results

On the public ImageNetâ€‘EEG split we obtain (single RTXÂ 3090Â 24â€¯GB):

| Setup                 | Topâ€‘1 Acc  | CLIP Matching (>Â 0.5) |
| --------------------- | ---------- | --------------------- |
| **Ours (EEGÂ +Â CLIP)** | **41.2â€¯%** | **67.8â€¯%**            |
| EEG Baseline          | 34.5â€¯%     | â€“                     |

Qualitative reconstructions and additional visuals are available in `images/result.png`.

---

## ðŸ“œ Citation

```bibtex
@article{zhang2025eeg2gaussian,
  title   = {EEG2Gaussian: Decoding and Visualizing Visualâ€‘Evoked EEG for VR Scenes Using 3D Gaussian Splatting},
  author  = {Zhang, Liming and Li, X.X. and Wang, X.X.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year    = {2025}
}
```

---

## ðŸ“ License

Released under the **MIT License**â€”see the [LICENSE](LICENSE) file for details.

---

## ðŸ™ Acknowledgements

- [OpenAIÂ CLIP](https://github.com/openai/CLIP) â€” visionâ€“language alignment
- [3D Gaussian Splatting](https://repo-supplied-link) â€” fast 3D scene reconstruction
- The ImageNetâ€‘EEG team and the openâ€‘source community for their invaluable resources.

=======
This is the EEG encoder section of the EEG2Gaussian project.
![alt text](images/overview.png)
![alt text](images/pipeline.png)
![alt text](images/result.png)
>>>>>>> 7438cc1171a1d896c677bf999526be40d35f943c
